---
layout:     post   				        # 使用的布局（不需要改）
title:      Hive的安装以及数据源上传 		   # 标题 
subtitle:                    #副标题
date:       2019-10-28 				    # 时间
author:     shexiaobin 				    # 作者
header-img:  img/post-bg-2015.jpg     	#这篇文章标题背景图片
catalog: true 						    # 是否归档
tags:								    #标签
    - Hadoop
---




# 安装hive

![image.png](https://cdn.nlark.com/yuque/0/2019/png/288250/1572196679432-a6ab26a3-79b7-4629-adce-58737738603d.png)

下载地址[http://mirror.bit.edu.cn/apache/hive/hive-3.1.1/](http://mirror.bit.edu.cn/apache/hive/hive-3.1.1/)

## 1. 解压hive安装包

```mysql
# 解压
tar -zxvf apache-hive-3.1.1-bin.tar.gz -C ~
# 创建软链接
ln -s apache-hive-3.1.1-bin hive

cd hive

ls
```

## 2.配置HIVE_HOME环境变量

```mysql
vi ~/.bashrc

export HIVE_HOME=/root/hive
export PATH=$HIVE_HOME/bin:$PATH

# 一定要记得这一步
source ~/.bashrc
```

![image.png](https://cdn.nlark.com/yuque/0/2019/png/288250/1572197004935-b26fb1ad-499e-47cd-adb0-d2aa8b80e966.png)



> 查看版本号 hive --version

![image.png](https://cdn.nlark.com/yuque/0/2019/png/288250/1572197087459-85b46fa9-051c-402e-ba19-d164e3dbde1e.png)

## 3.在hdfs上创建hive数据存放目录

```shell
hadoop fs -mkdir /tmp
hadoop fs -mkdir -p /user/hive/warehouse
hadoop fs -chmod g+w /tmp
hadoop fs -chmod g+w /user/hive/warehouse
```

## 4. 初始化hive库schma

```shell
# hive安装目录下执行下面命令初始化hive 默认数据库为derby:
cd hive
./bin/schematool -dbType derby -initSchema
```

- 初始化成功后就会在hive的安装目录下生成derby.log日志文件和metastore_db数据库目录,目录中存放的是hive的数据库信息.

![image.png](https://cdn.nlark.com/yuque/0/2019/png/288250/1572197281718-b604beb8-8f08-4e66-93d1-d6e3f79e4986.png)

## 5.启动hive

注意事项:

1.在高版本的hive已经添加安全认证机制,所有需要使用hadoop用户启动.

2.保证hadoop集群的状态是非安全模式下，使用一下命令查看到的状态是OFF

如果是ON状态，请使用``hadoop dfsadmin -safemode leave``命令关闭安全模式

当我们配置好hive的环境变量执行，直接使用hive命令启动hive的shell操作界面.

![image.png](https://cdn.nlark.com/yuque/0/2019/png/288250/1572197482802-7f089d75-c558-4528-93c9-2a429794dcb1.png)

>  **记得要进到hive目录下再使用hive命令** 
>
>  **使用show tables 如果安装成功会显示OK提示.** 

# 数据源上传

## 1. 单表

在home下创建datas目录,然后通过xftp 把数据源上传上去

![image.png](https://cdn.nlark.com/yuque/0/2019/png/288250/1572230093785-ccb7321f-a9d6-48ce-a27e-a5cad5e47294.png)

```shell
# 依次启动 Hadoop 与 hive进入hive 交互模式并创建库kaikeba
create database if not exists kaikeba;
use kaikeba;

create table if not exists user_info (
user_id  string,
user_name  string, 
sex  string,
age  int,
city  string,
firstactivetime  string,
level  int,
extra1  string,
extra2  map<string,string>)
row format DELIMITED FIELDS TERMINATED BY '\t'
COLLECTION ITEMS TERMINATED BY ','
MAP KEYS TERMINATED BY ':'
LINES TERMINATED BY '\n'
stored as textfile;
```



![image.png](https://cdn.nlark.com/yuque/0/2019/png/288250/1572230155554-4e36640d-6d8d-474b-a16e-6136e737f1c3.png)

### 加载数据源

```shell
load data local inpath 
'/home/datas/user_info/user_info.txt' 
overwrite into table user_info;
```

> **注意：上步如果出现错误** **建议重启3****台虚拟环境，然后每台都要关闭防火墙，重启hadoop** 
>
> **重启hive**
>
> **1. ****停止firewall**
>
> **``systemctl stop firewalld.service``** 
>
> **2. ****禁止firewall****开机启动**
>
> **``systemctl disable firewalld.service``** 

## 2. **分区表**

```
CREATE TABLE IF NOT EXISTS user_trade(
user_name  string,
piece  int,
price  double,
pay_amount  double,
goods_category  string,
pay_time  bigint)
partitioned by (dt string)
row format delimited fields terminated by '\t';
```

![image.png](https://cdn.nlark.com/yuque/0/2019/png/288250/1572230249955-b8bf990f-c3d2-4253-811e-64172d155cfe.png)

### 设置动态分区

```shell
set hive.exec.dynamic.partition=true;
set hive.exec.dynamic.partition.mode=nonstrict;    
set hive.exec.max.dynamic.partitions=10000;
set hive.exec.max.dynamic.partitions.pernode=10000;
```

![image.png](https://cdn.nlark.com/yuque/0/2019/png/288250/1572230297845-7148bdde-e141-400d-ac7b-6e9429d65e56.png)



### 查看hdfs上的文件

**用xshell 再次打开一个kkb001 上述保持不动做如下操作** 

![杀杀杀.png](https://cdn.nlark.com/yuque/0/2019/png/288250/1572230346721-4d25532d-0e47-4ac5-a298-1910a8e4b025.png)

### 上传数据到hdfs

```
 hdfs dfs -put /home/datas/user_trade/* /user/hive/warehouse/kaikeba.db/user_trade
```

![image.png](https://cdn.nlark.com/yuque/0/2019/png/288250/1572230407914-bba545a7-5270-42f2-bc65-cc3495d48820.png)

**msck repair table + 表名** 

![image.png](https://cdn.nlark.com/yuque/0/2019/png/288250/1572230462938-073cd12c-d77e-4687-a6f6-d9b3390473c9.png)

![image.png](https://cdn.nlark.com/yuque/0/2019/png/288250/1572230607882-d022711f-f2ee-4c9a-82e3-18823b6b05cf.png)

