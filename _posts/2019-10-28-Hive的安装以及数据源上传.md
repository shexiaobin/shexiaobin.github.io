---
layout:     post   				        # 使用的布局（不需要改）
title:      Hive的安装以及数据源上传 		   # 标题 
subtitle:                    #副标题
date:       2019-10-28 				    # 时间
author:     shexiaobin 				    # 作者
header-img:  img/post-bg-2015.jpg     	#这篇文章标题背景图片
catalog: true 						    # 是否归档
tags:								    #标签
    - Hadoop
---




# 安装hive

![image](https://user-images.githubusercontent.com/26622879/69488244-afca0f80-0ea1-11ea-8231-3d053b503787.png)

下载地址[http://mirror.bit.edu.cn/apache/hive/hive-3.1.1/](http://mirror.bit.edu.cn/apache/hive/hive-3.1.1/)

## 1. 解压hive安装包

```mysql
# 解压
tar -zxvf apache-hive-3.1.1-bin.tar.gz -C ~
# 创建软链接
ln -s apache-hive-3.1.1-bin hive

cd hive

ls
```

## 2.配置HIVE_HOME环境变量

```mysql
vi ~/.bashrc

export HIVE_HOME=/root/hive
export PATH=$HIVE_HOME/bin:$PATH

# 一定要记得这一步
source ~/.bashrc
```

![image](https://user-images.githubusercontent.com/26622879/69488160-a2f8ec00-0ea0-11ea-9093-0faa463faeed.png)



> 查看版本号 hive --version

![image](https://user-images.githubusercontent.com/26622879/69488167-be63f700-0ea0-11ea-99f4-2973b4d27e28.png)

## 3.在hdfs上创建hive数据存放目录

```shell
hadoop fs -mkdir /tmp
hadoop fs -mkdir -p /user/hive/warehouse
hadoop fs -chmod g+w /tmp
hadoop fs -chmod g+w /user/hive/warehouse
```

## 4. 初始化hive库schma

```shell
# hive安装目录下执行下面命令初始化hive 默认数据库为derby:
cd hive
./bin/schematool -dbType derby -initSchema
```

- 初始化成功后就会在hive的安装目录下生成derby.log日志文件和metastore_db数据库目录,目录中存放的是hive的数据库信息.

![image](https://user-images.githubusercontent.com/26622879/69488177-cfad0380-0ea0-11ea-86e8-80af60a8f1d1.png)

## 5.启动hive

注意事项:

1.在高版本的hive已经添加安全认证机制,所有需要使用hadoop用户启动.

2.保证hadoop集群的状态是非安全模式下，使用一下命令查看到的状态是OFF

如果是ON状态，请使用``hadoop dfsadmin -safemode leave``命令关闭安全模式

当我们配置好hive的环境变量执行，直接使用hive命令启动hive的shell操作界面.

![image](https://user-images.githubusercontent.com/26622879/69488184-e94e4b00-0ea0-11ea-881e-e75d11b46d94.png)

>  **记得要进到hive目录下再使用hive命令** 
>
>  **使用show tables 如果安装成功会显示OK提示.** 

# 数据源上传

## 1. 单表

在home下创建datas目录,然后通过xftp 把数据源上传上去

![image](https://user-images.githubusercontent.com/26622879/69488199-0aaf3700-0ea1-11ea-9cc2-c32ceafa4050.png)

```shell
# 依次启动 Hadoop 与 hive进入hive 交互模式并创建库kaikeba
create database if not exists kaikeba;
use kaikeba;

create table if not exists user_info (
user_id  string,
user_name  string, 
sex  string,
age  int,
city  string,
firstactivetime  string,
level  int,
extra1  string,
extra2  map<string,string>)
row format DELIMITED FIELDS TERMINATED BY '\t'
COLLECTION ITEMS TERMINATED BY ','
MAP KEYS TERMINATED BY ':'
LINES TERMINATED BY '\n'
stored as textfile;
```



![image](https://user-images.githubusercontent.com/26622879/69488210-24e91500-0ea1-11ea-95f9-86e0e4605074.png)

### 加载数据源

```shell
load data local inpath 
'/home/datas/user_info/user_info.txt' 
overwrite into table user_info;
```

> **注意：上步如果出现错误** **建议重启3****台虚拟环境，然后每台都要关闭防火墙，重启hadoop** 
>
> **重启hive**
>
> **1. ****停止firewall**
>
> **``systemctl stop firewalld.service``** 
>
> **2. ****禁止firewall****开机启动**
>
> **``systemctl disable firewalld.service``** 

## 2. **分区表**

```
CREATE TABLE IF NOT EXISTS user_trade(
user_name  string,
piece  int,
price  double,
pay_amount  double,
goods_category  string,
pay_time  bigint)
partitioned by (dt string)
row format delimited fields terminated by '\t';
```

![image](https://user-images.githubusercontent.com/26622879/69488218-36cab800-0ea1-11ea-9dff-000470b9aa30.png)

### 设置动态分区

```shell
set hive.exec.dynamic.partition=true;
set hive.exec.dynamic.partition.mode=nonstrict;    
set hive.exec.max.dynamic.partitions=10000;
set hive.exec.max.dynamic.partitions.pernode=10000;
```

![image](https://user-images.githubusercontent.com/26622879/69488222-464a0100-0ea1-11ea-850a-021d0802bbd9.png)



### 查看hdfs上的文件

**用xshell 再次打开一个kkb001 上述保持不动做如下操作** 

![image](https://user-images.githubusercontent.com/26622879/69488228-6b3e7400-0ea1-11ea-9c79-df1ff5588e5c.png)

### 上传数据到hdfs

```
 hdfs dfs -put /home/datas/user_trade/* /user/hive/warehouse/kaikeba.db/user_trade
```

![image](https://user-images.githubusercontent.com/26622879/69488231-7e514400-0ea1-11ea-83e9-dfbf55661192.png)

**msck repair table + 表名** 

![image](https://user-images.githubusercontent.com/26622879/69488235-89a46f80-0ea1-11ea-853e-5e9f257df569.png)

![image](https://user-images.githubusercontent.com/26622879/69488238-9aed7c00-0ea1-11ea-81a4-f72bdd155c50.png)

