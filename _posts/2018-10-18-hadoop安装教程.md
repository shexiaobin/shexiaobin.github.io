---
layout:     post   				        # 使用的布局（不需要改）
title:      Hadoop安装教程——单机/伪分布/完全分布式配置 		   # 标题 
subtitle:   Hello friend                #副标题
date:       2018-10-18 				    # 时间
author:     shexiaobin 				    # 作者
header-img:  img/post-bg-2015.jpg     	#这篇文章标题背景图片
catalog: true 						    # 是否归档
tags:								    #标签
    - Java
---




# 单机模式

- 1.1.1 安装前装备

- (1)安装Linux

   下载Ubuntu 16.04，下载地址：http://ftp.sjtu.edu.cn/ubuntu-cd/16.04.5/

    （a）Desktop    -->  桌面版，默认带了界面 ubuntu-16.04.5-desktop-amd64.iso

    （b）Server      --> 服务器版，默认没有带界面 ubuntu-16.04.5-server-amd64.iso

- （2）查看防火墙状态
    **查看防火墙状态**            
   ``sudo ufw status``
   **关闭防火墙**
``sudo  ufw disable``

- (3) 安装JDK

**解压到根目录：**
`tar -zxvf jdk-8u144-linux-x64.tar.gz -C ~`

**建一个软链接（方便使用）**

`ln -s jdk1.8.0_144 jdk `   (改名为jdk)

**配置环境变量**

``vi  ~/.bashrc``

```
export JAVA_HOME=/home/hadoop/jdk  (hadoop为用户名，jdk为jdk的安装目录，可使用软链接)

export PATH=$JAVA_HOME/bin:$PATH

export CLASSPATH=$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:.

```

变量生效：（修改配置后，一定要记住生效）

 ``source  ~/.bashrc``

**vi如何使用** 
>系统自带的vi很难用，建议安装vim

 ```
sudo apt-get install  vim    // 安装vim
输入`a`进入编辑模式
`esc` //退出编辑模式
`:wq` // 保存并退出
`:q`  //不保存退出
```

查看jdk是否安装成功
``java -version ``


- （4）Hadoop安装包解压
`tar -zxvf hadoop-2.7.3.tar.gz -C ~`

创建超链接：
`ln -s hadoop-2.7.3 hadoop`

配置环境变量：
`vi ~/.bashrc`

```
export HADOOP_HOME=/home/hadoop/hadoop
export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
```
变量生效：
`source  ~/.bashrc`

# 1.1.2 安装 （cd 到hadoop中的etc目录）

- （1）**修改配置**

`vi  hadoop-env.sh`

```
export JAVA_HOME=/home/hadoop/jdk (实际jdk的安装目录)
```
**查看hadoop是否安装成功**
`hadoop version`


# 1.2 伪分布模式

- 1.2.1 **安装前准备**
- (1) 参考上面1.1.1
 同1.1.1

- （2）配置主机名

sudo vi /etc/hosts   (前面加sudo，需要root权限)

```
191.168.1.51   node1.hadoop  node1

注：191.168.1.51 //本机实际ip，输入`ifconfig`可查看
    node1               //主机名
   `cat  /etc/hostname`    //查看主机名
    `vi   /etc/hostname`    //修改主机名

```

- （3）确认openssh-client、openssh-server是否安装

查看是否已经安装ssh  （xshell要连接上服务器也需要安装ssh）
`dpkg -l | grep openssh`

若没有，安装命令：
```
`sudo apt-get install openssh-client`
`sudo apt-get install openssh-server`
```
> ssh是目前较为可靠，专为远程登录会话和其他网络服务提供安全性的协议，利用ssh协议可以有效防止远程管理过程中的信息泄露问题。

- （4）免密码登录

通过ssh-keyen生成一个RSA的密钥对:

`ssh-keygen -t rsa -P '' `（P为大写，操作过程一路回车）

公钥追加到~/.ssh/authorized_keys文件中:

`ssh-copy-id -i  ~/.ssh/id_rsa.pub node1` 主机名(如上面都node1)

测试免密码登录：  `ssh node1`

# 1.2.2安装

- (1)  **修改配置文件** （hadoop/etc/hadoop）

`vi hadoop-env.sh`
```
export JAVA_HOME=/home/hadoop/jdk
```

`vi hdfs-site.xml`
```
<!--表示数据块的冗余度，默认：3-->

<property>
  <name>dfs.replication</name>
  <value>1</value>
</property>
```

`core-site.xml`

```
<!--配置NameNode地址,9000是RPC通信端口-->

<property>
   <name>fs.defaultFS</name>
   <value>hdfs://node1:9000</value>
</property>	

<!--HDFS数据保存在Linux的哪个目录，默认值是Linux的tmp目录-->
<property>
   <name>hadoop.tmp.dir</name>
   <value>/home/hadoop/hadoop/tmp</value>
</property>	
```
![image.png](https://upload-images.jianshu.io/upload_images/12269087-fd2806735847609a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


`mapred-site.xml`
>默认没有（cp mapred-site.xml.template mapred-site.xml）
```
<!--MR运行的框架-->
<property>
   <name>mapreduce.framework.name</name>
   <value>yarn</value>
</property>	
```
`yarn-site.xml`
```
<!--Yarn的主节点RM的位置-->
<property>
   <name>yarn.resourcemanager.hostname</name>
   <value>node1</value>
</property>	

<!--MapReduce运行方式：shuffle洗牌-->
<property>
   <name>yarn.nodemanager.aux-services</name>
   <value>mapreduce_shuffle</value>
</property>	
```

- (2) **格式化**
`hdfs namenode -format`

- (3) 启动停止Hadoop的环境
`start-all.sh`
`stop-all.sh`

- (4）测试
查看进程：
`jps`

![image.png](https://upload-images.jianshu.io/upload_images/12269087-3306c45b77bfb6d6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

**通过Web界面：（网址要改成自己的ip）**
HDFS:  http://191.168.1.51:50070  

http://191.168.1.51:50090

Yarn:  http://191.168.1.51:8088

# 1.3 完全分布式模式

安装规划
确定几个节点，Namenode、Datanode安装在哪几台机器上。
这里用两个Datanode，一个Namenode  
   每台机器参考上面“安装前准备操作”,同时增加下面几步：

- 2.1.1 安装前准备
- （1）参考上面1.1.1
同1.1.1

- （2）配置主机名

`sudo vi /etc/hosts`

```
191.168.1.51   node1.hadoop  node1
191.168.1.52   node2.hadoop  node2
191.168.1.53   node3.hadoop  node3
```

- (3) 安装ntp服务 （保证集群内所有主机时间同步）

$`sudo dpkg -l |grep ntp`

若NTP尚未安装就运行安装命令：

$ `sudo apt-get install ntp`

> ntp服务需要注意能连接网络，有什么用？
如果时间不一样，执行MapReduce程序的时候可能存在问题

- (4) 配置免密码登录：两两之间的免密码登录

```
每台机器上运行：
ssh-keygen -t rsa -P ''
ssh-copy-id -i  ~/.ssh/id_rsa.pub  node1
ssh-copy-id -i  ~/.ssh/id_rsa.pub  node2
ssh-copy-id -i  ~/.ssh/id_rsa.pub  node3
```

- (1)  **修改配置文件** （hadoop/etc/hadoop）

`vi hadoop-env.sh`
```
export JAVA_HOME=/home/hadoop/jdk
```

`vi hdfs-site.xml`
```
<!--表示数据块的冗余度，默认：3-->

<property>
  <name>dfs.replication</name>
  <value>2</value>
</property>
```

`core-site.xml`

```
<!--配置NameNode地址,9000是RPC通信端口-->

<property>
   <name>fs.defaultFS</name>
   <value>hdfs://node1:9000</value>
</property>	
<!--HDFS数据保存在Linux的哪个目录，默认值是Linux的tmp目录-->
<property>
   <name>hadoop.tmp.dir</name>
   <value>/home/hadoop/hadoop/tmp</value>
</property>	
```
![image.png](https://upload-images.jianshu.io/upload_images/12269087-fd2806735847609a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


`mapred-site.xml`
>默认没有（cp mapred-site.xml.template mapred-site.xml）
```
<!--MR运行的框架-->
<property>
   <name>mapreduce.framework.name</name>
   <value>yarn</value>
</property>	
```
`yarn-site.xml`
```
<!--Yarn的主节点RM的位置-->
<property>
   <name>yarn.resourcemanager.hostname</name>
   <value>node1</value>
</property>	

<!--MapReduce运行方式：shuffle洗牌-->
<property>
   <name>yarn.nodemanager.aux-services</name>
   <value>mapreduce_shuffle</value>
</property>	
```

`slaves`
```
`node2`
`node3`
```

- (2) 格式化NameNode
`hdfs namenode -format`

- (3)  把主节点上配置好的hadoop复制到从节点上
```
`scp -r hadoop-2.7.3/ hadoop@node2:/home/hadoop`
`scp -r hadoop-2.7.3/ hadoop@node3:/home/hadoop`

注意：hadoop@node2改为自己的用户名：shexiaobin@node2

/home/hadoop改为：/home/sheixaobin
```

- (4) `start-all.sh`

- (5)`jps` 看进程
**注意：node1不能出现datanode**

![image.png](https://upload-images.jianshu.io/upload_images/12269087-8be73e6ba4ef27d3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

通过Web界面：
```
HDFS:  http://191.168.1.51:50070 
 http://191.168.1.51:50090
Yarn:  http://191.168.1.51:8088
```

# Mapreduce 测试
通过mapreduce：
```
但预先要往hdfs传一个文件，如何操作?

1.   Linux目录下，随意一个目录，创建一个文本文件data.txt，里面写些内容。
2.   hdfs dfs  -mkdir /input
3.   hdfs dfs -put data.txt /input    ---上传
4.   hdfs dfs -ls /input            --查看

```
`hadoop jar hadoop-mapreduce-examples-2.7.3.jar wordcount /input/data.txt  /output`

注意：要cd 到对应的目录再打开终端
      cd hadoop/hadoop-2.7.3/share/hadoop/mapreduce
     可以输入：locate +文件名 找到路径

最后查看结果： `hdfs dfs -ls /output`
![image.png](https://upload-images.jianshu.io/upload_images/12269087-16f9fa5ac83c4587.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

hdfs dfs -cat /output/part-r-00000
![image.png](https://upload-images.jianshu.io/upload_images/12269087-1d273b7081180a77.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

namenode未启动后遗症：拒绝连接 9000端口没启动，导致input文件无法创建
![image.png](https://upload-images.jianshu.io/upload_images/12269087-0167750936f0a9a9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


