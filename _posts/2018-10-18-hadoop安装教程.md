---
layout:     post   				        # 使用的布局（不需要改）
title:      Hadoop安装教程——单机/伪分布/完全分布式配置 		   # 标题 
subtitle:   Hello Mayer                #副标题
date:       2018-10-18 				    # 时间
author:     shexiaobin 				    # 作者
header-img:  img/post-bg-2015.jpg     	#这篇文章标题背景图片
catalog: true 						    # 是否归档
tags:								    #标签
    - Hadoop
---




# 单机模式

- 1.1.1 安装前装备

- (1)安装Linux

   下载Ubuntu 16.04，下载地址：http://ftp.sjtu.edu.cn/ubuntu-cd/16.04.5/

    （a）Desktop    -->  桌面版，默认带了界面 ubuntu-16.04.5-desktop-amd64.iso

    （b）Server      --> 服务器版，默认没有带界面 ubuntu-16.04.5-server-amd64.iso

- （2）查看防火墙状态
    **查看防火墙状态**            
   ``sudo ufw status``
   **关闭防火墙**
``sudo  ufw disable``

- (3) 安装JDK

**解压到根目录：**
``tar -zxvf jdk-8u144-linux-x64.tar.gz -C ~``

**建一个软链接（方便使用）**

``ln -s jdk1.8.0_144 jdk ``   (改名为jdk)

**配置环境变量**

``vi  ~/.bashrc``

```
export JAVA_HOME=/home/hadoop/jdk  (hadoop为用户名，jdk为jdk的安装目录，可使用软链接)

export PATH=$JAVA_HOME/bin:$PATH

export CLASSPATH=$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:.

```

变量生效：（修改配置后，一定要记住生效）

 ``source  ~/.bashrc``

**vi如何使用** 
>系统自带的vi很难用，建议安装vim

 ```
sudo apt-get install  vim    // 安装vim
输入`a`进入编辑模式
`esc` //退出编辑模式
`:wq` // 保存并退出
`:q`  //不保存退出
 ```

查看jdk是否安装成功
``java -version ``


- （4）Hadoop安装包解压
``tar -zxvf hadoop-2.7.3.tar.gz -C ~``

创建超链接：
`ln -s hadoop-2.7.3 hadoop`

配置环境变量：
`vi ~/.bashrc`

```
export HADOOP_HOME=/home/hadoop/hadoop
export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
```

变量生效：

``source  ~/.bashrc``

# 1.1.2 安装 （cd 到hadoop中的etc目录）

- （1）**修改配置**

``vi  hadoop-env.sh``

```
export JAVA_HOME=/home/hadoop/jdk (实际jdk的安装目录)
```

**查看hadoop是否安装成功**
``hadoop version``


# 1.2 伪分布模式

- 1.2.1 **安装前准备**
- (1) 参考上面1.1.1
 同1.1.1

- （2）配置主机名

sudo vi /etc/hosts   (前面加sudo，需要root权限)

```
191.168.1.51   node1.hadoop  node1

注：191.168.1.51 //本机实际ip，输入`ifconfig`可查看
    node1               //主机名
   ``cat  /etc/hostname``   //查看主机名
    ``vi   /etc/hostname``    //修改主机名

```

- （3）确认openssh-client、openssh-server是否安装

查看是否已经安装ssh  （xshell要连接上服务器也需要安装ssh）
``dpkg -l | grep openssh``

若没有，安装命令：

```
`sudo apt-get install openssh-client`
`sudo apt-get install openssh-server`
```


> ssh是目前较为可靠，专为远程登录会话和其他网络服务提供安全性的协议，利用ssh协议可以有效防止远程管理过程中的信息泄露问题。


- （4）免密码登录

通过ssh-keyen生成一个RSA的密钥对:

``ssh-keygen -t rsa -P '' ``（P为大写，操作过程一路回车）

公钥追加到~/.ssh/authorized_keys文件中:

``ssh-copy-id -i  ~/.ssh/id_rsa.pub node1`` 主机名(如上面都node1)

测试免密码登录：  ``ssh node1``

# 1.2.2安装

- (1)  **修改配置文件** （hadoop/etc/hadoop）

``vi hadoop-env.sh``

```
export JAVA_HOME=/home/hadoop/jdk
```

``vi hdfs-site.xml``

```
<!--表示数据块的冗余度，默认：3-->

<property>
  <name>dfs.replication</name>
  <value>1</value>
</property>
```

``core-site.xml``

```
<!--配置NameNode地址,9000是RPC通信端口-->

<property>
   <name>fs.defaultFS</name>
   <value>hdfs://node1:9000</value>
</property>	

<!--HDFS数据保存在Linux的哪个目录，默认值是Linux的tmp目录-->
<property>
   <name>hadoop.tmp.dir</name>
   <value>/home/hadoop/hadoop/tmp</value>
</property>	
```

![img](https://cdn.nlark.com/yuque/0/2019/png/288250/1572181976616-416c229d-68ed-4549-aeeb-0426705d1d00.png)


``mapred-site.xml``

>默认没有（cp mapred-site.xml.template mapred-site.xml）


```
<!--MR运行的框架-->
<property>
   <name>mapreduce.framework.name</name>
   <value>yarn</value>
</property>	
```

``yarn-site.xml``


```
<!--Yarn的主节点RM的位置-->
<property>
   <name>yarn.resourcemanager.hostname</name>
   <value>node1</value>
</property>	

<!--MapReduce运行方式：shuffle洗牌-->
<property>
   <name>yarn.nodemanager.aux-services</name>
   <value>mapreduce_shuffle</value>
</property>	
```



- (2) **格式化**
``hdfs namenode -format``

- (3) 启动停止Hadoop的环境
``start-all.sh``

``stop-all.sh``


- (4）测试
查看进程：
``jps``

![img](https://cdn.nlark.com/yuque/0/2019/png/288250/1572182016620-855de615-1d9c-4767-93bb-93b20598a6c5.png)

**通过Web界面：（网址要改成自己的ip）**
HDFS:  http://191.168.1.51:50070  


http://191.168.1.51:50090


Yarn:  http://191.168.1.51:8088



# 1.3 完全分布式模式

安装规划
确定几个节点，Namenode、Datanode安装在哪几台机器上。
这里用两个Datanode，一个Namenode  
   每台机器参考上面“安装前准备操作”,同时增加下面几步：

- 2.1.1 安装前准备
- （1）参考上面1.1.1
同1.1.1

- （2）配置主机名

``sudo vi /etc/hosts``


```
191.168.1.51   node1.hadoop  node1   #主机名.用户名 用户名相同的情况下可以省略，保险起见不要省
191.168.1.52   node2.hadoop  node2
191.168.1.53   node3.hadoop  node3
```

- (3) 安装ntp服务 （保证集群内所有主机时间同步）

$``sudo dpkg -l |grep ntp``

若NTP尚未安装就运行安装命令：

$ ``sudo apt-get install ntp``

> ntp服务需要注意能连接网络，有什么用？
如果时间不一样，执行MapReduce程序的时候可能存在问题

- (4) 配置免密码登录：两两之间的免密码登录

```
每台机器上运行：
ssh-keygen -t rsa -P ''
ssh-copy-id -i  ~/.ssh/id_rsa.pub  node1
ssh-copy-id -i  ~/.ssh/id_rsa.pub  node2
ssh-copy-id -i  ~/.ssh/id_rsa.pub  node3
```

- (1)  **修改配置文件** （hadoop/etc/hadoop）

``vi hadoop-env.sh``

```
export JAVA_HOME=/home/hadoop/jdk
```

``vi hdfs-site.xml``
```
<!--表示数据块的冗余度，默认：3-->

<property>
  <name>dfs.replication</name>
  <value>2</value>
</property>
```

``core-site.xml``

```
<!--配置NameNode地址,9000是RPC通信端口-->

<property>
   <name>fs.defaultFS</name>
   <value>hdfs://node1:9000</value>
</property>	
<!--HDFS数据保存在Linux的哪个目录，默认值是Linux的tmp目录-->
<property>
   <name>hadoop.tmp.dir</name>
   <value>/home/hadoop/hadoop/tmp</value>
</property>	
```

![img](https://cdn.nlark.com/yuque/0/2019/png/288250/1572182049786-5137b9fa-2915-46cb-99f1-93f43191fbad.png)


``mapred-site.xml``

>默认没有（cp mapred-site.xml.template mapred-site.xml）


```
<!--MR运行的框架-->
<property>
   <name>mapreduce.framework.name</name>
   <value>yarn</value>
</property>	
```


``yarn-site.xml``

```
<!--Yarn的主节点RM的位置-->
<property>
   <name>yarn.resourcemanager.hostname</name>
   <value>node1</value>
</property>	

<!--MapReduce运行方式：shuffle洗牌-->
<property>
   <name>yarn.nodemanager.aux-services</name>
   <value>mapreduce_shuffle</value>
</property>	
```

``slaves``


```
`node2`
`node3`
```

- (2) 格式化NameNode
``hdfs namenode -format``


- (3)  把主节点上配置好的hadoop复制到从节点上


```
``scp -r hadoop-2.7.3/ hadoop@node2:/home/hadoop``
``scp -r hadoop-2.7.3/ hadoop@node3:/home/hadoop``

注意：hadoop@node2改为自己的用户名：shexiaobin@node2

/home/hadoop改为：/home/sheixaobin
```

- (4) ``start-all.sh``


- (5)``jps`` 看进程
**注意：node1不能出现datanode**

![img](https://cdn.nlark.com/yuque/0/2019/png/288250/1572182079667-e5212413-cc58-4b85-8f48-220bf5b70608.png)

通过Web界面：

```
HDFS:  http://191.168.1.51:50070 
 http://191.168.1.51:50090
Yarn:  http://191.168.1.51:8088
```

# Mapreduce 测试
通过mapreduce：

```
但预先要往hdfs传一个文件，如何操作?

1.   Linux目录下，随意一个目录，创建一个文本文件data.txt，里面写些内容。
2.   hdfs dfs  -mkdir /input
3.   hdfs dfs -put data.txt /input    ---上传
4.   hdfs dfs -ls /input            --查看

```

``hadoop jar hadoop-mapreduce-examples-2.7.3.jar wordcount /input/data.txt  /output``

注意：要cd 到对应的目录再打开终端
      cd hadoop/hadoop-2.7.3/share/hadoop/mapreduce
     可以输入：locate +文件名 找到路径

最后查看结果： ``hdfs dfs -ls /output``


![img](https://cdn.nlark.com/yuque/0/2019/png/288250/1572182104545-dc0f6409-3fce-4ba9-b4bb-abed964386af.png)

hdfs dfs -cat /output/part-r-00000


![img](https://cdn.nlark.com/yuque/0/2019/png/288250/1572182130808-853bec0d-67fa-4047-8db8-eb08af645aa6.png)

namenode未启动后遗症：拒绝连接 9000端口没启动，导致input文件无法创建

![img](https://cdn.nlark.com/yuque/0/2019/png/288250/1572182159463-aa731233-6daf-406b-989f-e51683f30e63.png)


